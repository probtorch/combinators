{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nix/store/lq2q3qv0fiyyrprfs1s1yb42w9lvd6ja-python3-3.8.6-env/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'targets': [[g0]MultivariateNormal(),\n",
       "  [β=0.1429][g1]Tempered(\n",
       "    (density1): [g0]MultivariateNormal()\n",
       "    (density2): [g7]RingGMM()\n",
       "  ),\n",
       "  [β=0.2857][g2]Tempered(\n",
       "    (density1): [g0]MultivariateNormal()\n",
       "    (density2): [g7]RingGMM()\n",
       "  ),\n",
       "  [β=0.4286][g3]Tempered(\n",
       "    (density1): [g0]MultivariateNormal()\n",
       "    (density2): [g7]RingGMM()\n",
       "  ),\n",
       "  [β=0.5714][g4]Tempered(\n",
       "    (density1): [g0]MultivariateNormal()\n",
       "    (density2): [g7]RingGMM()\n",
       "  ),\n",
       "  [β=0.7143][g5]Tempered(\n",
       "    (density1): [g0]MultivariateNormal()\n",
       "    (density2): [g7]RingGMM()\n",
       "  ),\n",
       "  [β=0.8571][g6]Tempered(\n",
       "    (density1): [g0]MultivariateNormal()\n",
       "    (density2): [g7]RingGMM()\n",
       "  ),\n",
       "  [g7]RingGMM()],\n",
       " 'forwards': [MultivariateNormalKernel(\n",
       "    (net): ResMLPJ(\n",
       "      (joint): Sequential(\n",
       "        (0): Linear(in_features=2, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (mu): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=2, bias=True)\n",
       "      )\n",
       "      (cov): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=2, bias=True)\n",
       "      )\n",
       "    )\n",
       "  ),\n",
       "  MultivariateNormalKernel(\n",
       "    (net): ResMLPJ(\n",
       "      (joint): Sequential(\n",
       "        (0): Linear(in_features=2, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (mu): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=2, bias=True)\n",
       "      )\n",
       "      (cov): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=2, bias=True)\n",
       "      )\n",
       "    )\n",
       "  ),\n",
       "  MultivariateNormalKernel(\n",
       "    (net): ResMLPJ(\n",
       "      (joint): Sequential(\n",
       "        (0): Linear(in_features=2, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (mu): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=2, bias=True)\n",
       "      )\n",
       "      (cov): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=2, bias=True)\n",
       "      )\n",
       "    )\n",
       "  ),\n",
       "  MultivariateNormalKernel(\n",
       "    (net): ResMLPJ(\n",
       "      (joint): Sequential(\n",
       "        (0): Linear(in_features=2, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (mu): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=2, bias=True)\n",
       "      )\n",
       "      (cov): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=2, bias=True)\n",
       "      )\n",
       "    )\n",
       "  ),\n",
       "  MultivariateNormalKernel(\n",
       "    (net): ResMLPJ(\n",
       "      (joint): Sequential(\n",
       "        (0): Linear(in_features=2, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (mu): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=2, bias=True)\n",
       "      )\n",
       "      (cov): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=2, bias=True)\n",
       "      )\n",
       "    )\n",
       "  ),\n",
       "  MultivariateNormalKernel(\n",
       "    (net): ResMLPJ(\n",
       "      (joint): Sequential(\n",
       "        (0): Linear(in_features=2, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (mu): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=2, bias=True)\n",
       "      )\n",
       "      (cov): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=2, bias=True)\n",
       "      )\n",
       "    )\n",
       "  ),\n",
       "  MultivariateNormalKernel(\n",
       "    (net): ResMLPJ(\n",
       "      (joint): Sequential(\n",
       "        (0): Linear(in_features=2, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (mu): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=2, bias=True)\n",
       "      )\n",
       "      (cov): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=2, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )],\n",
       " 'reverses': [MultivariateNormalKernel(\n",
       "    (net): ResMLPJ(\n",
       "      (joint): Sequential(\n",
       "        (0): Linear(in_features=2, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (mu): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=2, bias=True)\n",
       "      )\n",
       "      (cov): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=2, bias=True)\n",
       "      )\n",
       "    )\n",
       "  ),\n",
       "  MultivariateNormalKernel(\n",
       "    (net): ResMLPJ(\n",
       "      (joint): Sequential(\n",
       "        (0): Linear(in_features=2, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (mu): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=2, bias=True)\n",
       "      )\n",
       "      (cov): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=2, bias=True)\n",
       "      )\n",
       "    )\n",
       "  ),\n",
       "  MultivariateNormalKernel(\n",
       "    (net): ResMLPJ(\n",
       "      (joint): Sequential(\n",
       "        (0): Linear(in_features=2, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (mu): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=2, bias=True)\n",
       "      )\n",
       "      (cov): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=2, bias=True)\n",
       "      )\n",
       "    )\n",
       "  ),\n",
       "  MultivariateNormalKernel(\n",
       "    (net): ResMLPJ(\n",
       "      (joint): Sequential(\n",
       "        (0): Linear(in_features=2, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (mu): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=2, bias=True)\n",
       "      )\n",
       "      (cov): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=2, bias=True)\n",
       "      )\n",
       "    )\n",
       "  ),\n",
       "  MultivariateNormalKernel(\n",
       "    (net): ResMLPJ(\n",
       "      (joint): Sequential(\n",
       "        (0): Linear(in_features=2, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (mu): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=2, bias=True)\n",
       "      )\n",
       "      (cov): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=2, bias=True)\n",
       "      )\n",
       "    )\n",
       "  ),\n",
       "  MultivariateNormalKernel(\n",
       "    (net): ResMLPJ(\n",
       "      (joint): Sequential(\n",
       "        (0): Linear(in_features=2, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (mu): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=2, bias=True)\n",
       "      )\n",
       "      (cov): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=2, bias=True)\n",
       "      )\n",
       "    )\n",
       "  ),\n",
       "  MultivariateNormalKernel(\n",
       "    (net): ResMLPJ(\n",
       "      (joint): Sequential(\n",
       "        (0): Linear(in_features=2, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (mu): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=2, bias=True)\n",
       "      )\n",
       "      (cov): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=2, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )]}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import torch\n",
    "import math\n",
    "from torch import nn, Tensor\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import trange\n",
    "from typing import Tuple\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import combinators.trace.utils as trace_utils\n",
    "from combinators.trace.utils import RequiresGrad\n",
    "from combinators.tensor.utils import autodevice, kw_autodevice, copy, show\n",
    "from combinators.densities import MultivariateNormal, Tempered, RingGMM, Normal\n",
    "from combinators.densities.kernels import MultivariateNormalKernel, MultivariateNormalLinearKernel, NormalLinearKernel\n",
    "from combinators.nnets import ResMLPJ\n",
    "from combinators.objectives import nvo_rkl, nvo_avo\n",
    "from combinators import Forward, Reverse, Propose\n",
    "from combinators.stochastic import RandomVariable, ImproperRandomVariable\n",
    "from combinators.metrics import effective_sample_size, log_Z_hat\n",
    "import visualize as V\n",
    "\n",
    "def mk_kernel(from_:int, to_:int, std:float, num_hidden:int, learn_cov=True):\n",
    "    embedding_dim = 2\n",
    "    return MultivariateNormalKernel(\n",
    "        ext_from=f'g{from_}',\n",
    "        ext_to=f'g{to_}',\n",
    "        loc=torch.zeros(2, **kw_autodevice()),\n",
    "        cov=torch.eye(2, **kw_autodevice())*std**2,\n",
    "        learn_cov=learn_cov,\n",
    "        net=ResMLPJ(\n",
    "            dim_in=2,\n",
    "            dim_hidden=num_hidden,\n",
    "            dim_out=embedding_dim).to(autodevice()))\n",
    "\n",
    "def mk_mnlinear_kernel(from_:int, to_:int, std:float, dim:int):\n",
    "    return MultivariateNormalLinearKernel(\n",
    "        ext_from=f'g{from_}',\n",
    "        ext_to=f'g{to_}',\n",
    "        loc=torch.zeros(dim, **kw_autodevice()),\n",
    "        cov=torch.eye(dim, **kw_autodevice())*std**2)\n",
    "\n",
    "def mk_nlinear_kernel(from_:int, to_:int, std:float, dim:int):\n",
    "    return NormalLinearKernel(ext_from=f'g{from_}', ext_to=f'g{to_}')\n",
    "\n",
    "def anneal_to_ring(num_targets, n=2):\n",
    "    g0, gK = mk_ring(num_targets, n)\n",
    "    return anneal_between(g0, gK, num_targets)\n",
    "\n",
    "def mk_ring(num_targets, n):\n",
    "    assert n > 1\n",
    "    g0 = mk_mvn(0, 0, std=5)\n",
    "    gK = RingGMM(loc_scale=10, scale=0.5, count=8 if n == \"paper\" else n, name=f\"g{num_targets - 1}\").to(autodevice())\n",
    "    return g0, gK\n",
    "\n",
    "def anneal_between(left, right, total_num_targets):\n",
    "    proposal_std = total_num_targets\n",
    "\n",
    "    # Make an annealing path\n",
    "    betas = torch.arange(0., 1., 1./(total_num_targets - 1))[1:] # g_0 is beta=0\n",
    "    path = [Tempered(f'g{k}', left, right, beta) for k, beta in zip(range(1,total_num_targets-1), betas)]\n",
    "    path = [left] + path + [right]\n",
    "\n",
    "    assert len(path) == total_num_targets # sanity check that the betas line up\n",
    "    return path\n",
    "\n",
    "\n",
    "def anneal_between_mvns(left_loc, right_loc, total_num_targets):\n",
    "    g0 = mk_mvn(0, left_loc)\n",
    "    gK =  mk_mvn(total_num_targets-1, right_loc)\n",
    "\n",
    "    return anneal_between(g0, gK, total_num_targets)\n",
    "\n",
    "def anneal_between_ns(left_loc, right_loc, total_num_targets):\n",
    "    g0 = mk_n(0, left_loc)\n",
    "    gK =  mk_n(total_num_targets-1, right_loc)\n",
    "\n",
    "    return anneal_between(g0, gK, total_num_targets)\n",
    "\n",
    "def mk_mvn(i, loc, std=1):\n",
    "    return MultivariateNormal(name=f'g{i}', loc=torch.ones(2, **kw_autodevice())*loc, cov=torch.eye(2, **kw_autodevice())*std**2)\n",
    "\n",
    "def mk_n(i, loc):\n",
    "    return Normal(name=f'g{i}', loc=torch.ones(1, **kw_autodevice())*loc, scale=torch.ones(1, **kw_autodevice())**2)\n",
    "\n",
    "def mk_model(num_targets:int):\n",
    "    return dict(\n",
    "        targets=anneal_to_ring(num_targets, n=8),\n",
    "        forwards=[mk_kernel(from_=i, to_=i+1, std=1., num_hidden=64) for i in range(num_targets-1)],\n",
    "        reverses=[mk_kernel(from_=i+1, to_=i, std=1., num_hidden=64) for i in range(num_targets-1)],\n",
    "\n",
    "#         targets=anneal_between_mvns(0, num_targets*2, num_targets),\n",
    "#         forwards=[mk_kernel(from_=i, to_=i+1, std=1., num_hidden=64) for i in range(num_targets-1)],\n",
    "#         reverses=[mk_kernel(from_=i+1, to_=i, std=1., num_hidden=64) for i in range(num_targets-1)],\n",
    "\n",
    "#         targets=anneal_between_mvns(0, num_targets*2, num_targets),\n",
    "#         forwards=[mk_mnlinear_kernel(from_=i, to_=i+1, std=1., dim=2) for i in range(num_targets-1)],\n",
    "#         reverses=[mk_mnlinear_kernel(from_=i+1, to_=i, std=1., dim=2) for i in range(num_targets-1)],\n",
    "\n",
    "        # NOTES: Anneal between 2 1d guassians with a linear kernel: 2 steps\n",
    "        # annealing does not learn the forward kernel in the first step, but learns both in the second step. \n",
    "#         targets=anneal_between_ns(0, num_targets*2, num_targets),\n",
    "#         forwards=[mk_nlinear_kernel(from_=i, to_=i+1, std=1., dim=1) for i in range(num_targets-1)],\n",
    "#         reverses=[mk_nlinear_kernel(from_=i+1, to_=i, std=1., dim=1) for i in range(num_targets-1)],\n",
    "\n",
    "#         targets=[mk_mvn(i, i*2) for i in range(num_targets)],\n",
    "#         forwards=[mk_kernel(from_=i, to_=i+1, std=1., num_hidden=32) for i in range(num_targets-1)],\n",
    "#         reverses=[mk_kernel(from_=i+1, to_=i, std=1., num_hidden=32) for i in range(num_targets-1)],\n",
    "\n",
    "#         targets=[mk_mvn(i, i*2) for i in range(num_targets)],\n",
    "#         forwards=[mk_mnlinear_kernel(from_=i, to_=i+1, std=1., dim=2) for i in range(num_targets-1)],\n",
    "#         reverses=[mk_mnlinear_kernel(from_=i+1, to_=i, std=1., dim=2) for i in range(num_targets-1)],\n",
    "\n",
    "        # NOTES: With 1 intermediate density between 2 1d guassians with a linear kernel everything is fine\n",
    "#         targets=[mk_n(i, i*2) for i in range(num_targets)],\n",
    "#         forwards=[mk_nlinear_kernel(from_=i, to_=i+1, std=1., dim=1) for i in range(num_targets-1)],\n",
    "#         reverses=[mk_nlinear_kernel(from_=i+1, to_=i, std=1., dim=1) for i in range(num_targets-1)],\n",
    "    )\n",
    "K = 8\n",
    "\n",
    "mk_model(K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "from torch import nn, Tensor\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import trange\n",
    "from typing import Tuple\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import combinators.trace.utils as trace_utils\n",
    "from combinators.tensor.utils import autodevice, kw_autodevice\n",
    "from combinators.densities import MultivariateNormal, Tempered, RingGMM\n",
    "from combinators.densities.kernels import MultivariateNormalKernel\n",
    "from combinators.nnets import ResMLPJ\n",
    "from combinators.objectives import nvo_rkl\n",
    "from combinators import Forward, Reverse, Propose\n",
    "from combinators.stochastic import RandomVariable, ImproperRandomVariable\n",
    "from combinators.metrics import effective_sample_size, log_Z_hat\n",
    "import visualize as V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from main import mk_model, mk_kernel\n",
    "from tqdm.notebook import trange, tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from combinators import Forward\n",
    "\n",
    "def sample_along(proposal, kernels, sample_shape=(2000,)):\n",
    "    samples = []\n",
    "    tr, out = proposal(sample_shape=sample_shape)\n",
    "    samples.append(out)\n",
    "    for k in forwards:\n",
    "        proposal = Forward(k, proposal)\n",
    "        tr, out = proposal(sample_shape=sample_shape)\n",
    "        samples.append(out)\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main() arguments\n",
    "seed=1\n",
    "eval_break = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "torch.manual_seed(seed)\n",
    "num_samples = 256\n",
    "sample_shape=(num_samples,)\n",
    "\n",
    "# Models\n",
    "out = mk_model(K)\n",
    "targets, forwards, reverses = [[m.to(autodevice()) for m in out[n]] for n in ['targets', 'forwards', 'reverses']]\n",
    "\n",
    "assert all([len(list(k.parameters())) >  0 for k in [*forwards, *reverses]])\n",
    "\n",
    "# logging\n",
    "writer = SummaryWriter()\n",
    "loss_ct, loss_sum, loss_avgs, loss_all = 0, 0.0, [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[g0]MultivariateNormal(), [β=0.1429][g1]Tempered(\n",
      "  (density1): [g0]MultivariateNormal()\n",
      "  (density2): [g7]RingGMM()\n",
      "), [β=0.2857][g2]Tempered(\n",
      "  (density1): [g0]MultivariateNormal()\n",
      "  (density2): [g7]RingGMM()\n",
      "), [β=0.4286][g3]Tempered(\n",
      "  (density1): [g0]MultivariateNormal()\n",
      "  (density2): [g7]RingGMM()\n",
      "), [β=0.5714][g4]Tempered(\n",
      "  (density1): [g0]MultivariateNormal()\n",
      "  (density2): [g7]RingGMM()\n",
      "), [β=0.7143][g5]Tempered(\n",
      "  (density1): [g0]MultivariateNormal()\n",
      "  (density2): [g7]RingGMM()\n",
      "), [β=0.8571][g6]Tempered(\n",
      "  (density1): [g0]MultivariateNormal()\n",
      "  (density2): [g7]RingGMM()\n",
      "), [g7]RingGMM()]\n"
     ]
    }
   ],
   "source": [
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MultivariateNormalKernel(\n",
      "  (net): ResMLPJ(\n",
      "    (joint): Sequential(\n",
      "      (0): Linear(in_features=2, out_features=64, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (mu): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=2, bias=True)\n",
      "    )\n",
      "    (cov): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      "), MultivariateNormalKernel(\n",
      "  (net): ResMLPJ(\n",
      "    (joint): Sequential(\n",
      "      (0): Linear(in_features=2, out_features=64, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (mu): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=2, bias=True)\n",
      "    )\n",
      "    (cov): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      "), MultivariateNormalKernel(\n",
      "  (net): ResMLPJ(\n",
      "    (joint): Sequential(\n",
      "      (0): Linear(in_features=2, out_features=64, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (mu): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=2, bias=True)\n",
      "    )\n",
      "    (cov): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      "), MultivariateNormalKernel(\n",
      "  (net): ResMLPJ(\n",
      "    (joint): Sequential(\n",
      "      (0): Linear(in_features=2, out_features=64, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (mu): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=2, bias=True)\n",
      "    )\n",
      "    (cov): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      "), MultivariateNormalKernel(\n",
      "  (net): ResMLPJ(\n",
      "    (joint): Sequential(\n",
      "      (0): Linear(in_features=2, out_features=64, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (mu): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=2, bias=True)\n",
      "    )\n",
      "    (cov): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      "), MultivariateNormalKernel(\n",
      "  (net): ResMLPJ(\n",
      "    (joint): Sequential(\n",
      "      (0): Linear(in_features=2, out_features=64, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (mu): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=2, bias=True)\n",
      "    )\n",
      "    (cov): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      "), MultivariateNormalKernel(\n",
      "  (net): ResMLPJ(\n",
      "    (joint): Sequential(\n",
      "      (0): Linear(in_features=2, out_features=64, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (mu): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=2, bias=True)\n",
      "    )\n",
      "    (cov): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")]\n"
     ]
    }
   ],
   "source": [
    "print(forwards)\n",
    "\n",
    "# _ = [print(p) for f in forwards  for p in f.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MultivariateNormalKernel(\n",
      "  (net): ResMLPJ(\n",
      "    (joint): Sequential(\n",
      "      (0): Linear(in_features=2, out_features=64, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (mu): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=2, bias=True)\n",
      "    )\n",
      "    (cov): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      "), MultivariateNormalKernel(\n",
      "  (net): ResMLPJ(\n",
      "    (joint): Sequential(\n",
      "      (0): Linear(in_features=2, out_features=64, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (mu): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=2, bias=True)\n",
      "    )\n",
      "    (cov): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      "), MultivariateNormalKernel(\n",
      "  (net): ResMLPJ(\n",
      "    (joint): Sequential(\n",
      "      (0): Linear(in_features=2, out_features=64, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (mu): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=2, bias=True)\n",
      "    )\n",
      "    (cov): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      "), MultivariateNormalKernel(\n",
      "  (net): ResMLPJ(\n",
      "    (joint): Sequential(\n",
      "      (0): Linear(in_features=2, out_features=64, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (mu): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=2, bias=True)\n",
      "    )\n",
      "    (cov): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      "), MultivariateNormalKernel(\n",
      "  (net): ResMLPJ(\n",
      "    (joint): Sequential(\n",
      "      (0): Linear(in_features=2, out_features=64, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (mu): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=2, bias=True)\n",
      "    )\n",
      "    (cov): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      "), MultivariateNormalKernel(\n",
      "  (net): ResMLPJ(\n",
      "    (joint): Sequential(\n",
      "      (0): Linear(in_features=2, out_features=64, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (mu): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=2, bias=True)\n",
      "    )\n",
      "    (cov): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      "), MultivariateNormalKernel(\n",
      "  (net): ResMLPJ(\n",
      "    (joint): Sequential(\n",
      "      (0): Linear(in_features=2, out_features=64, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (mu): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=2, bias=True)\n",
      "    )\n",
      "    (cov): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")]\n"
     ]
    }
   ],
   "source": [
    "print(reverses)\n",
    "\n",
    "# _ = [print(p) for f in reverses for p in f.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from combinators.objectives import mb0, mb1, _estimate_mc, eval_nrep\n",
    "optimizer = torch.optim.Adam([dict(params=x.parameters()) for x in [*forwards, *reverses]], lr=1e-3)\n",
    "lazy_i, i = 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43efd3c28aed42d195a45871d4e6c550",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-8204c55615a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mp_ext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mextend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPropose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp_ext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproposal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mq_ext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_dims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mp_prv_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nix/store/lq2q3qv0fiyyrprfs1s1yb42w9lvd6ja-python3-3.8.6-env/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/combinators/combinators/inference.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sample_dims, *shared_args, **shared_kwargs)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mconditions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond_trace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopytrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproposal_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRequiresGrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mYES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mReverse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0mtarget_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mshared_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_dims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mshared_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mconditions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mjoint_proposal_trace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproposal_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nix/store/lq2q3qv0fiyyrprfs1s1yb42w9lvd6ja-python3-3.8.6-env/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/combinators/combinators/inference.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, cond_trace, sample_dims, *program_args, **program_kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m#self.kernel.update_conditions(self.observations)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0mkernel_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mprogram_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_dims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m         \u001b[0;31m# self.kernel.clear_conditions()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nix/store/lq2q3qv0fiyyrprfs1s1yb42w9lvd6ja-python3-3.8.6-env/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/combinators/combinators/kernel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, cond_trace, cond_outs, sample_dims, validate)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m# grab anything that is missing from the cond_trace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mfull_trace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopytraces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfull_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nix/store/lq2q3qv0fiyyrprfs1s1yb42w9lvd6ja-python3-3.8.6-env/lib/python3.8/site-packages/typeguard/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0mmemo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_CallMemo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_localns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0mcheck_argument_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m         \u001b[0mcheck_return_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/combinators/combinators/trace/utils.py\u001b[0m in \u001b[0;36mcopytraces\u001b[0;34m(requires_grad, detach, overwrite, *traces)\u001b[0m\n\u001b[1;32m    130\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0mnewrv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopyrv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_requires_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdetach\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m             \u001b[0mnewtr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewrv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnewtr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nix/store/lq2q3qv0fiyyrprfs1s1yb42w9lvd6ja-python3-3.8.6-env/lib/python3.8/site-packages/typeguard/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0mmemo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_CallMemo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_localns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0mcheck_argument_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m         \u001b[0mcheck_return_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/combinators/combinators/trace/utils.py\u001b[0m in \u001b[0;36mcopyrv\u001b[0;34m(rv, requires_grad, provenance, deepcopy_value)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mRVClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprovenance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprovenance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_pmf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_use_pmf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mRVClass\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mImproperRandomVariable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mRVClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_density_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_density_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprovenance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprovenance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/combinators/combinators/stochastic.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, log_density_fn, value, provenance, mask)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_density_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprovenance\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mProvenance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mProvenance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOBSERVED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0mlog_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_density_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_prob\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprovenance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprovenance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_density_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_density_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/combinators/combinators/densities/__init__.py\u001b[0m in \u001b[0;36mlog_density_fn\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdensity1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m                \u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdensity2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/combinators/combinators/densities/__init__.py\u001b[0m in \u001b[0;36mlog_prob\u001b[0;34m(g, value)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlog_density_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_density_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDensity\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;31m# with torch.no_grad(): # you can't learn anything about this density for the moment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/combinators/combinators/densities/__init__.py\u001b[0m in \u001b[0;36mlog_density_fn\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mlds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m             \u001b[0mld_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# + log_weights[i]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0mlds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mld_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0mlds_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nix/store/lq2q3qv0fiyyrprfs1s1yb42w9lvd6ja-python3-3.8.6-env/lib/python3.8/site-packages/torch/distributions/multivariate_normal.py\u001b[0m in \u001b[0;36mlog_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_batch_mahalanobis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unbroadcasted_scale_tril\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0mhalf_log_det\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unbroadcasted_scale_tril\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiagonal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mhalf_log_det\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nix/store/lq2q3qv0fiyyrprfs1s1yb42w9lvd6ja-python3-3.8.6-env/lib/python3.8/site-packages/torch/distributions/multivariate_normal.py\u001b[0m in \u001b[0;36m_batch_mahalanobis\u001b[0;34m(bL, bx)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mflat_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_L\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# shape = c x b x n\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mflat_x_swap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflat_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# shape = b x n x c\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mM_swap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtriangular_solve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_x_swap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_L\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupper\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# shape = b x c\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0mM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mM_swap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# shape = c x b\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_iterations=5000\n",
    "lazy_i = i\n",
    "with trange(num_iterations) as bar:\n",
    "    for i in bar:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        i += lazy_i\n",
    "        q0 = targets[0]\n",
    "        p_prv_tr, out0 = q0(sample_shape=sample_shape)\n",
    "\n",
    "        loss = torch.zeros(1, **kw_autodevice())\n",
    "        lw, lvss = torch.zeros(sample_shape, **kw_autodevice()), []\n",
    "        \n",
    "        for k, (fwd, rev, q, p) in enumerate(zip(forwards, reverses, targets[:-1], targets[1:])):\n",
    "            q.with_observations(trace_utils.copytrace(p_prv_tr, detach=p_prv_tr.keys()))\n",
    "\n",
    "            q_ext = Forward(fwd, q, _step=k)\n",
    "            p_ext = Reverse(p, rev, _step=k)\n",
    "            extend = Propose(target=p_ext, proposal=q_ext, _step=k)\n",
    "            state, lv = extend(sample_shape=sample_shape, sample_dims=0)\n",
    "\n",
    "            p_prv_tr = state.target.trace\n",
    "            p.clear_observations()\n",
    "            q.t()\n",
    "            lw += lv\n",
    "#             loss += nvo_rkl(lw, lv, state.proposal.trace[f'g{k}'], state.target.trace[f'g{k+1}'])\n",
    "            loss += nvo_avo(lv)\n",
    "            lvss.append(lv)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # REPORTING\n",
    "            # ---------------------------------------\n",
    "            # ESS\n",
    "            lvs = torch.stack(lvss, dim=0)\n",
    "            lws = torch.cumsum(lvs, dim=1)\n",
    "            ess = effective_sample_size(lws, sample_dims=-1)\n",
    "            for step, x in zip(range(1,len(ess)+1), ess):\n",
    "                writer.add_scalar(f'ess/step-{step}', x, i)\n",
    "\n",
    "            # logZhat\n",
    "            lzh = log_Z_hat(lws, sample_dims=-1)\n",
    "            for step, x in zip(range(1,len(lzh)+1), lzh):\n",
    "                writer.add_scalar(f'log_Z_hat/step-{step}', x, i)\n",
    "\n",
    "            # loss\n",
    "            loss_ct += 1\n",
    "            loss_scalar = loss.detach().cpu().mean().item()\n",
    "            writer.add_scalar('loss', loss_scalar, i)\n",
    "            loss_sum += loss_scalar\n",
    "\n",
    "            # progress bar\n",
    "            if i % 10 == 0:\n",
    "                loss_avg = loss_sum / loss_ct\n",
    "                loss_template = 'loss={}{:.4f}'.format('' if loss_avg < 0 else ' ', loss_avg)\n",
    "                logZh_template = 'logZhat[-1]={:.4f}'.format(lzh[-1].cpu().item())\n",
    "                ess_template = 'ess[-1]={:.4f}'.format(ess[-1].cpu().item())\n",
    "                loss_ct, loss_sum  = 0, 0.0\n",
    "                bar.set_postfix_str(\"; \".join([loss_template, ess_template, logZh_template]))\n",
    "\n",
    "            # show samples\n",
    "            if i % (eval_break + 1) == 0:\n",
    "                samples = sample_along(targets[0], forwards)\n",
    "                fig = V.scatter_along(samples)\n",
    "                writer.add_figure('overview', fig, global_step=i, close=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = sample_along(targets[0], forwards)\n",
    "plot_type = len(samples[0].squeeze().shape)\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from scipy.interpolate import interpn\n",
    "from matplotlib import cm\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "def scatter(xs, lws=None, c='C0', ax=None, show=False):\n",
    "    xs = xs.squeeze().detach().cpu().numpy()\n",
    "    assert len(xs.shape) == 2\n",
    "    inplace = ax is not None\n",
    "    cm_endpoints = [(i, (*colors.to_rgb(c), i)) for i in [0.0, 1.0]]\n",
    "    lin_alpha = colors.LinearSegmentedColormap.from_list('incr_alpha', cm_endpoints)\n",
    "    fig = None\n",
    "    plt.scatter(*xs.T, c=None, cmap=lin_alpha)\n",
    "\n",
    "    if show:\n",
    "        plt.show()\n",
    "    return fig if fig is not None else ax\n",
    "\n",
    "def scatter_together(samples):\n",
    "    fig = plt.figure(figsize=(5*len(samples), 5))\n",
    "    gspec = gridspec.GridSpec(ncols=len(samples), nrows=1, figure=fig)\n",
    "\n",
    "    for i, xs in enumerate(samples):\n",
    "        ax = fig.add_subplot(gspec[0, i])\n",
    "        scatter(xs)\n",
    "    return fig\n",
    "\n",
    "if plot_type == 1:\n",
    "    print(\";  \".join([\"{:.4f}\".format(ss.mean().cpu().item()) for ss in samples]))\n",
    "elif plot_type == 2:\n",
    "    fig = scatter_together(samples)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
